{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, pickle, argparse, networks, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from edge_promoting import edge_promoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'MyC1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(os.path.join(project_name + '_results', 'Reconstruction')):\n",
    "    os.makedirs(os.path.join(project_name + '_results', 'Reconstruction'))\n",
    "if not os.path.isdir(os.path.join(project_name + '_results', 'Transfer')):\n",
    "    os.makedirs(os.path.join(project_name + '_results', 'Transfer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, input_channel, output_channel, n_layers = 5, hidden_size = 32):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.output_channel = output_channel\n",
    "        self.hidden_size = hidden_size\n",
    "        self.convs = []\n",
    "        \n",
    "        self.convs.append(nn.Conv2d(input_channel, hidden_size, kernel_size = 3, stride = 1, padding = 1))\n",
    "        current_channel = hidden_size\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            self.convs.append(nn.Conv2d(current_channel, current_channel*2, kernel_size = 3, stride = 2, padding = 1))\n",
    "            self.convs.append(nn.LeakyReLU(0.2, True))\n",
    "            \n",
    "            self.convs.append(nn.Conv2d(current_channel*2, current_channel*4, kernel_size = 3, stride = 1, padding = 1))\n",
    "            nn.InstanceNorm2d(current_channel * 4),\n",
    "            self.convs.append(nn.LeakyReLU(0.2, True))\n",
    "            # enlarge the channel by 2 times every 2 layers\n",
    "            current_channel *= 4\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList(self.convs)\n",
    "\n",
    "        utils.initialize_weights(self)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        # input = torch.cat((input1, input2), 1)\n",
    "        output = self.conv_layers(input)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvInstanceNormLeakyRelu(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel, kernel_size, stride, padding, leaky_rate = 0.2):\n",
    "        super(ConvInstanceNormLeakyRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channel, out_channels, kernel_size = kernel_size, stride = stride, padding = padding)\n",
    "        self.InstanceNorm = nn.InstanceNorm2d(output_channel)\n",
    "        self.relu = nn.LeakyReLU(leaky_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.InstanceNorm(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_block(nn.Module):\n",
    "    def __init__(self, channel, kernel, stride, padding):\n",
    "        super(resnet_block, self).__init__()\n",
    "        self.channel = channel\n",
    "        self.kernel = kernel\n",
    "        self.strdie = stride\n",
    "        self.padding = padding\n",
    "        self.conv1 = nn.Conv2d(channel, channel, kernel, stride, padding)\n",
    "        self.conv1_norm = nn.InstanceNorm2d(channel)\n",
    "        self.conv2 = nn.Conv2d(channel, channel, kernel, stride, padding)\n",
    "        self.conv2_norm = nn.InstanceNorm2d(channel)\n",
    "\n",
    "        utils.initialize_weights(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.copy()\n",
    "        x = F.relu(self.conv1_norm(self.conv1(x)), True)\n",
    "        x = self.conv2_norm(self.conv2(x))\n",
    "\n",
    "        return x + identity #Elementwise Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_dw(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                nn.ReLU(inplace=True),\n",
    "    \n",
    "                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwise_separable_conv(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super(depthwise_separable_conv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=3, padding=1, groups=nin)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwise_separable_conv_stride2(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super(depthwise_separable_conv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=3, padding=1, stride = 2, groups=nin)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, input_channel, output_channel, n_block_layers = 8, hidden_size = 64):\n",
    "        super(generator, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.output_channel = output_channel\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # The generator have three parts: 1. down samples 2. resnet blocks  3. up samples\n",
    "        self.n_block_layers = n_block_layers\n",
    "        \n",
    "        self.down_convs = [ConvInstanceNormLeakyRelu(input_channel, hidden_size, 3, 1, 3), \\\n",
    "                           ConvInstanceNormLeakyRelu(hidden_size, hidden_size, 3, 1, 1), \\\n",
    "                           depthwise_separable_conv(hidden_size, hidden_size*2), \\\n",
    "                           ConvInstanceNormLeakyRelu(hidden_size*2, hidden_size*2, 3, 1, 1), \\\n",
    "                           depthwise_separable_conv(hidden_size*2, hidden_size*2), \\\n",
    "                           depthwise_separable_conv(hidden_size*2, hidden_size*4), \\\n",
    "                           ConvInstanceNormLeakyRelu(hidden_size*4, hidden_size*4, 3, 1, 1)]\n",
    "        \n",
    "\n",
    "        self.resnet_blocks = []\n",
    "        for i in range(n_block_layers):\n",
    "            self.resnet_blocks.append(resnet_block(hidden_size * 4, 3, 1, 1))\n",
    "\n",
    "\n",
    "        # basically, nn.ConvTranspose2d is more adopted in GANs than nn.Upsample\n",
    "        self.up_convs = [nn.ConvTranspose2d(hidden_size*4, hidden_size*4, 3, 2, 1, 1), #k3n128s1/2\n",
    "                            nn.Conv2d(nf * 2, nf * 2, 3, 1, 1), #k3n128s1\n",
    "                            nn.InstanceNorm2d(nf * 2),\n",
    "                            nn.LeakyReLU(leaky_rate),\n",
    "                            nn.ConvTranspose2d(nf * 2, nf, 3, 2, 1, 1), #k3n64s1/2\n",
    "                            nn.Conv2d(nf, nf, 3, 1, 1), #k3n64s1\n",
    "                            nn.InstanceNorm2d(nf),\n",
    "                            nn.LeakyReLU(leaky_rate),\n",
    "                            nn.Conv2d(nf, out_nc, 7, 1, 3), #k7n3s1\n",
    "                            nn.Hardtanh()]\n",
    "        \n",
    "        \n",
    "        self.down_convs_layers = nn.Sequential(*self.down_convs)\n",
    "        self.resnet_blocks_layers = nn.Sequential(*self.resnet_blocks)\n",
    "        self.up_convs_layers = nn.Sequential(*self.up_convs)\n",
    "\n",
    "        utils.initialize_weights(self)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = self.down_convs_layers(input)\n",
    "        x = self.resnet_blocks_layers(x)\n",
    "        output = self.up_convs_layers(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(os.path.join('data', tgt_data_dir, 'pair')):\n",
    "    print('edge-promoting start!!')\n",
    "    edge_promoting(os.path.join('data', tgt_data_dir, 'train'), os.path.join('data', args.tgt_data, 'pair'))\n",
    "else:\n",
    "    print('edge-promoting already done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2\n",
    "# Create a black image\n",
    "image = np.zeros((512,512,3), np.uint8)\n",
    "# Draw a diagonal blue line with thickness of 5 px\n",
    "for i in range(100):\n",
    "    i = random.randint(0, 512)\n",
    "    j = random.randint(0, 512)\n",
    "    k = random.randint(0, 14)-7\n",
    "    l = random.randint(0, 10)-5\n",
    "    \n",
    "    cv2.line(image,(i,j),(i+k,j+l),(255, 0, 0),2)\n",
    "\n",
    "img = Image.fromarray(image, 'RGB')\n",
    "img.save('my.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
